{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application d'extractions des relations sociales entre entités nommées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Régler le problème des NaN en prenant en compte les 'Titres' ? Régler le probleme de symétrie des NaN\n",
    "- Penser aux words-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('stanford-corenlp-full-2018-10-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_NE(text,PERSON):\n",
    "    \"\"\" Extrait les entités nommées d'un texte (text) et les stocke dans une liste (PERSON).\"\"\"\n",
    "    NE = nlp.ner(text)\n",
    "    for elt in NE :\n",
    "        if 'PERSON' in elt :\n",
    "            PERSON.append(elt[0])\n",
    "\n",
    "    return(list(set(PERSON)))\n",
    "    \n",
    "def init_relationship(RELATIONSHIP,PERSON) :\n",
    "    \"\"\" Initialise un dictionnaire (RELATIONSHIP) sur la base d'une liste (PERSON) d'entité nommée. \"\"\"\n",
    "    for p in PERSON : \n",
    "        RELATIONSHIP[p] = []\n",
    "\n",
    "def extract_dependencies(text_tokens,DEPENDENCY) :\n",
    "    \"\"\"\n",
    "    Extrait les dépendances 'nmod:poss' et 'appos' au sein d'un texte découpé par phrases (text_tokens) et les insère dans DEPENDENCY.\n",
    "    \n",
    "    arguments : \n",
    "    \n",
    "    text_tokens : liste contenant des listes, chaque 'sous-liste' contient elle une phrase du texte d'origine.\n",
    "    DEPENDENCY : tableau qui contient dans chaque colonne les dépendances grammaticales liées à une phrase.\n",
    "    \n",
    "    \"\"\"\n",
    "    nb_line = 0\n",
    "    for line in text_tokens  :\n",
    "        parsing = nlp.dependency_parse(line)\n",
    "        for elt in parsing:\n",
    "\n",
    "            if ('nmod:poss' in elt) :\n",
    "                DEPENDENCY[nb_line] = DEPENDENCY[nb_line] + [(elt)]\n",
    "\n",
    "            elif('appos' in elt) : \n",
    "                DEPENDENCY[nb_line] = DEPENDENCY[nb_line] + [(elt)]\n",
    "        nb_line+=1\n",
    "    nlp.close()\n",
    "    \n",
    "def make_relation(dep,dependencies,nb_line):\n",
    "    \"\"\" \n",
    "    Crée un quadruplé qui correspond à une relation valide sous la forme (personne1,relation,personne2,ligne du texte\n",
    "    où la relation a été identifiée).\n",
    "    \n",
    "        Arguments :\n",
    "        dep : une dépendance de la forme ('nature de la dépendance',mot1,mot2)\n",
    "        dependencies : liste de dépendances contenues dans la même ligne de texte que 'dep'\n",
    "        nb_line : numéro de la ligne du texte où la dépendance a été récupérée\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #On vérifie que la dépendance est bien de type 'nmod:poss'\n",
    "    if(dep[0]=='nmod:poss') :\n",
    "        \n",
    "        # Si il n'y a pas d'autres dépendance dans la phrase, alors on ne pourra pas extraire les 2 personnages\n",
    "        # On renvoie donc un quadruplé de type ('NaN',relation,personnage2,numéro de la ligne dans le texte)\n",
    "        if (dependencies == []):\n",
    "            return(('NaN',dep[1],dep[2],nb_line))\n",
    "        \n",
    "        #Sinon...\n",
    "        else :\n",
    "            #..on va chercher dans le reste des dépendances...\n",
    "            for elt in dependencies :\n",
    "                #..une apposition.\n",
    "                if (elt[0]=='appos'):\n",
    "                    \n",
    "                    #Si l'élement (elt[1]) (qui est un personnage) de l'apposition est identique à celui de notre nmod:poss (dep[1])...\n",
    "                    #..cela signifie qu'ils sont liés par un élément commun (qui est la relation dans le texte)\n",
    "                    if(dep[1]==elt[1]) :\n",
    "                        #Alors on retourne le quadruplé (personnage1,relation,personnage2,numéro de la ligne dans le texte)\n",
    "                        return((elt[2],dep[1],dep[2],nb_line))\n",
    "        \n",
    "    return((0,0,0))\n",
    "\n",
    "def replace_by_NE(text_split, PERSON):\n",
    "    \"\"\"Remplace toutes les occurences de la liste 'to_replace' par l'entité nommée à laquelle\n",
    "    elles font référence dans le texte \"\"\"\n",
    "    \n",
    "    to_replace = ['he','she','his','him','her','He','She','His','Her','Him']\n",
    "    result = \"\"\n",
    "    tmp_NE = \"\"\n",
    "    \n",
    "    for elt in text_split :\n",
    "        \n",
    "        tmp = re.sub('\\W+','',elt)\n",
    "        \n",
    "        if(tmp in PERSON):\n",
    "            tmp_NE = tmp\n",
    "            #result = result + elt + \" \" \n",
    "        \n",
    "        if(elt in to_replace) :\n",
    "            \n",
    "            #Ici on rajoute le suffixe \"'s\" quand on rencontre 'his' ou 'her' car sinon on risque de changer les dépendances grammaticales\n",
    "            #Et l'analyseur de dépendance risque de ne pas détecter un nmod:poss ou une apposition\n",
    "            \n",
    "            if(elt==\"his\" or elt==\"her\") :\n",
    "                result = result + tmp_NE+\"'s'\" + \" \"\n",
    "            else :\n",
    "                result = result  + tmp_NE + \" \"\n",
    "        \n",
    "        else : \n",
    "            result = result + elt + \" \"\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "    \n",
    "def fill_relationship(DEPENDENCY,TOKENS,LINKS,RELATIONSHIP):\n",
    "    \n",
    "    \"\"\"\n",
    "    Remplis le dictionnaire RELATIONSHIP avec les relations qui ont pu être extraites à l'aide de la fonction\n",
    "    'make_relation()'\n",
    "    \n",
    "    arg : \n",
    "    \n",
    "    DEPENDENCY : Le tableau de dépendances dont on a parlé dans les fonctions précédentes\n",
    "    \n",
    "    TOKENS : Une liste de liste. Chaque sous-liste contient une phrase du texte qui a été découpée en 'token' dont\n",
    "    les indices des mots correspondent à ceux présents dans les dépendances du tableau DEPENDENCY. Cette liste va\n",
    "    nous permettre de transformer un indice en mot pour pouvoir avoir une sortie compréhensible.\n",
    "    \n",
    "    RELATIONSHIP : Dans la description de la fonction\n",
    "    \n",
    "    LINKS : Liste qui contient les relations possibles entre des personnages\n",
    "    \"\"\"\n",
    "    nb_line = 0\n",
    "    tmp = []\n",
    "    encoded_relationship = []\n",
    "    id_NaN = 0\n",
    "    \n",
    "    #Pour toutes les dépendances qu'on a recueillis dans le tableau DEPENDENCY on créer les relations qui existent\n",
    "    #en utilisant la fonction make_relation et on les stocke dans la liste tmp\n",
    "    for elt in DEPENDENCY :\n",
    "        try :\n",
    "            tmp.append(make_relation(elt[0],elt[1:],nb_line))\n",
    "            nb_line+=1\n",
    "\n",
    "        except : \n",
    "            nb_line+=1\n",
    "\n",
    "    #Pour chaque élément de la liste tmp, on remplit la liste \"encoded_relationship\" de tous les éléments validés\n",
    "    for t in tmp : \n",
    "        if(t!=(0,0,0)) :\n",
    "            encoded_relationship.append(t)\n",
    "    \n",
    "    #Cette boucle va permettre de traduire une relation de type (1,mother,3,5) en (Gertrude,mother,Hamlet) et la stocker\n",
    "    #dans le dictionnaire RELATIONSHIP\n",
    "    for r in encoded_relationship :\n",
    "\n",
    "        try :\n",
    "            line = r[3]\n",
    "            perso2 = r[0]-1\n",
    "            lien = r[1]-1\n",
    "            perso1 = r[2]-1\n",
    "\n",
    "\n",
    "            try :\n",
    "\n",
    "                if((TOKENS[line][lien]) in LINKS) :\n",
    "                    RELATIONSHIP[(TOKENS[line][perso1])] += [(TOKENS[line][lien],TOKENS[line][perso2])]\n",
    "\n",
    "            except :\n",
    "\n",
    "                if((TOKENS[line][lien]) in LINKS) :\n",
    "                    RELATIONSHIP[(TOKENS[line][perso1])] = [(TOKENS[line][lien],TOKENS[line][perso2])]\n",
    "\n",
    "\n",
    "        except :\n",
    "\n",
    "            line = r[3]\n",
    "            lien = r[1]-1\n",
    "            perso1 = r[2]-1\n",
    "\n",
    "            if((TOKENS[line][lien]) in LINKS) :\n",
    "                RELATIONSHIP[str(r[0])+str(id_NaN)] = [(TOKENS[line][lien],TOKENS[line][perso1])]\n",
    "\n",
    "                id_NaN +=1\n",
    "\n",
    "def make_correspondance(RELATIONSHIP,LINK_CORRESPONDANCE):\n",
    "    \"\"\"\n",
    "    Créer un dictionnaire dans lequel on trouve la symétrie de chaque relation présente dans le dictionnaire RELATIONSHIP\n",
    "    \n",
    "    Par exemple : \n",
    "    RELATIONSHIP : Hamlet : [(mother,Gertrude)] -> new_RELATIONSHIP : Gertrude : [(child,Hamlet)]\n",
    "    (Hamlet a pour mère Gertrude) -> (Gertrude a pour fils Hamlet)\n",
    "    \n",
    "    \"\"\"\n",
    "    new_RELATIONSHIP = {}\n",
    "    \n",
    "    for elt in RELATIONSHIP : \n",
    "        for i in RELATIONSHIP[elt] :\n",
    "\n",
    "            try :\n",
    "                new_RELATIONSHIP[i[1]] += [(LINK_CORRESPONDANCE[i[0]],elt)]\n",
    "                \n",
    "            except : \n",
    "\n",
    "                new_RELATIONSHIP[i[1]] = [(LINK_CORRESPONDANCE[i[0]],elt)]\n",
    "    return new_RELATIONSHIP\n",
    "\n",
    "def merge_dictionnary(dict1,dict2) : \n",
    "    \"\"\"Fusionne deux dictionnaire (va nous permettre de fusionner RELATIONSHIP et son symétrique)\"\"\"\n",
    "    for elt in dict2 :\n",
    "        for i in dict2[elt] :\n",
    "            try :\n",
    "                dict1[elt] += [i]\n",
    "            except : \n",
    "                dict1[elt] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Hamlet.txt','r+')\n",
    "text = file.read()\n",
    "text = text.replace(\"’\\n\",\"\\n\")\n",
    "PERSON = []\n",
    "DEPENDENCY = [[]]*len(text)\n",
    "TOKENS = []\n",
    "RELATIONSHIP = {}\n",
    "LINKS = ['son','father','mother','daughter','cousin','siblings','husband','wife','spouses','brother','sister','friend','girlfriend','boyfriend']\n",
    "LINK_CORRESPONDANCE = {\n",
    "    'son' : 'parent',\n",
    "    'father' : 'child',\n",
    "    'mother' : 'child',\n",
    "    'daughter' : 'parent',\n",
    "    'cousin' : 'cousin',\n",
    "    'siblings' : 'siblings',\n",
    "    'husband' : 'wife',\n",
    "    'wife' : 'husband',\n",
    "    'spouses' : 'spouses',\n",
    "    'brother' : 'siblings',\n",
    "    'sister' : 'siblings',\n",
    "    'friend' : 'friend',\n",
    "    'girlfriend' : 'couple',\n",
    "    'boyfriend' : 'couple'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hamlet': [], 'Gertrude': [], 'Claudius': [], 'Horatio': [], 'Ophelia': [], 'Mother': []}\n"
     ]
    }
   ],
   "source": [
    "PERSON = extract_NE(text,PERSON)\n",
    "init_relationship(RELATIONSHIP,PERSON)\n",
    "\n",
    "print(RELATIONSHIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_text = text.split()\n",
    "text = replace_by_NE(tmp_text,PERSON)\n",
    "text_tokens = sent_tokenize(text)\n",
    "\n",
    "for line in text_tokens : \n",
    "    TOKENS.append(nlp.word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing = nlp.dependency_parse(text)        \n",
    "extract_dependencies(text_tokens,DEPENDENCY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a un problème : \n",
    "\n",
    "- On a utilisé la tokenization par phrase de la librairie, c'est à dire qu'on a découpé le texte par phrase avec une liste qui contient dans chacune de ses cases une phrase du texte.\n",
    "\n",
    "    - Le problème : La fonction n'a pas toujours découpé le texte par phrase (voir par exemple la case numéro 5 dans laquelle on retrouve 2 phrases)\n",
    "\n",
    "\n",
    "\n",
    "- On a, pour chacune des cases, utilisé l'analyseur de dépendences qui nous permet d'avoir les relations nmod:pos et appos entre les mots pour chacune des phrases qu'on a tokénizé.\n",
    "\n",
    "    - Le problème est que l'analyseur de dépendences, lui, découpe correctement les phrases. Ainsi, lorsqu'il nous donne l'indice d'un mot, il se base sur son découpage et non celui de la fonction qu'on a utilisé pour découper nos phrases, ce faisant, les indices des mots ne correspondent plus entre notre phrase du texte tokénisé et notre phrase du texte analysé.\n",
    "\n",
    "\n",
    "Solution temporaire : \n",
    "\n",
    "Le problème vient des caractères spéciaux \"’\" qui encadrent les dialogues, il suffit de les supprimer pour ce texte précis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_relationship(DEPENDENCY,TOKENS,RELATIONSHIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "corresponding_RELATIONSHIP = make_correspondance(RELATIONSHIP,LINK_CORRESPONDANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hamlet': [('mother', 'Gertrude'),\n",
       "  ('friend', 'Horatio'),\n",
       "  ('girlfriend', 'Ophelia')],\n",
       " 'Gertrude': [],\n",
       " 'Claudius': [],\n",
       " 'Horatio': [],\n",
       " 'Ophelia': [('brother', 'Laertes')],\n",
       " 'Mother': [],\n",
       " 'NaN0': [('father', 'Hamlet')],\n",
       " 'NaN1': [('father', 'Hamlet')],\n",
       " 'NaN2': [('father', 'Hamlet')],\n",
       " 'NaN3': [('friend', 'Hamlet')]}"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RELATIONSHIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Laertes': [('siblings', 'Ophelia')],\n",
       " 'Gertrude': [('child', 'Hamlet')],\n",
       " 'Horatio': [('friend', 'Hamlet')],\n",
       " 'Ophelia': [('couple', 'Hamlet')],\n",
       " 'Hamlet': [('child', 'NaN0'),\n",
       "  ('child', 'NaN1'),\n",
       "  ('child', 'NaN2'),\n",
       "  ('friend', 'NaN3')]}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_RELATIONSHIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hamlet': [('mother', 'Gertrude'),\n",
       "  ('friend', 'Horatio'),\n",
       "  ('girlfriend', 'Ophelia'),\n",
       "  ('child', 'NaN0'),\n",
       "  ('child', 'NaN1'),\n",
       "  ('child', 'NaN2'),\n",
       "  ('friend', 'NaN3')],\n",
       " 'Gertrude': [('child', 'Hamlet')],\n",
       " 'Claudius': [],\n",
       " 'Horatio': [('friend', 'Hamlet')],\n",
       " 'Ophelia': [('brother', 'Laertes'), ('couple', 'Hamlet')],\n",
       " 'Mother': [],\n",
       " 'NaN0': [('father', 'Hamlet')],\n",
       " 'NaN1': [('father', 'Hamlet')],\n",
       " 'NaN2': [('father', 'Hamlet')],\n",
       " 'NaN3': [('friend', 'Hamlet')],\n",
       " 'Laertes': [('siblings', 'Ophelia')]}"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dictionnary(RELATIONSHIP,corresponding_RELATIONSHIP)\n",
    "RELATIONSHIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
